<!DOCTYPE html><!-- 让浏览器得知自己处理的是html -->
<html lang="en">

<!--对文本进行操作	-->
<!--a表示创建超链接，href是链接到的那个东西，target选择新开网页打开链接或者在原网页打开-->
<!--b表示粗体  em表示斜体  s表示删除线-->

<head>
<!--提供有关文档内容和标注信息-->
<meta charset="utf-8"/>
<title>CFP</title>
<!--有head必须有title-->
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="Webflow" name="generator"/>
<link href=".\css\CVPR2020.css" rel="stylesheet" type="text/css"/>
<!--链接一个css--> 
<script src=".\css\CVPR2020.js" type="text/javascript"></script> 
<script type="text/javascript">WebFont.load({  google: {    families: ["Roboto:300,regular,500","Roboto Condensed:300,regular,700"," Roboto Slab:300,regular,700","Arbutus Slab:regular"]  }});</script> 
<script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
</head>

<body>
<div data-collapse="medium" data-animation="default" data-duration="400" class="navigation w-nav">
  <div class="w-container"><a href="#" class="brand-link w-nav-brand">
    <div class="logo-text">CFP</div>
    </a>
    <nav role="navigation" class="nav-menu w-nav-menu"> <a href="#abstract" class="nav-link w-nav-link">Abstract and Motivation</a> <a href="#topics" class="nav-link w-nav-link">Topics of Interest</a> <a href="#dates" class="nav-link w-nav-link">Submission Deadline</a> <a href="#guest" class="nav-link w-nav-link">Guest Editors</a></nav>
  </div>
</div>
<div data-animation="slide" data-duration="500" data-infinite="1" class="slider w-slider">
  <div class="w-slider-mask">
    <div class="slide _1 w-slide">
      <div class="w-container"></div>
    </div>
    <div class="slide _2 w-slide">
      <div class="w-container"></div>
    </div>
    <div class="slide _3 w-slide">
      <div class="w-container"></div>
    </div>
  </div>
  <div class="w-slider-arrow-left">
    <div class="w-icon-slider-left"></div>
  </div>
  <div class="w-slider-arrow-right">
    <div class="w-icon-slider-right"></div>
  </div>
  <div class="w-slider-nav w-round"></div>
</div>
<div class="section main w-hidden-small w-hidden-tiny">
  <div class="container w-container">
    <h1 class="main-heading">Call For Papers <br/><br/>
      IEEE Transactions on Pattern Analysis and Machine Intelligence<br/><br/>
      Special Issue on <strong>Learning with Fewer Labels in Computer Vision</strong></h1>
  </div>
</div>
<div id="abstract">
	<div class="section-10 w-hidden-small w-hidden-tiny">
  <div class="w-container">
    <h2 class="heading-11">Abstract and Motivation</h2>
    <div>
      <div class="text-block-8">The past several years have witnessed an explosion of interest in and a dizzyingly fast development of machine learning, a subﬁeld of artiﬁcial intelligence.  Foremost among these approaches are Deep Neural Networks (DNNs) that can learn powerful feature representations with multiple levels of abstraction directly from data when large amounts of labeled data is available.  One of the core computer vision areas, namely, object classiﬁcation achieved a signiﬁcant breakthrough result with a deep convolutional neural network and the large scale ImageNet dataset, which is arguably what reignited the ﬁeld of artiﬁcial neural networks and triggered the recent revolution in Artiﬁcial Intelligence (AI). Nowadays, artiﬁcial intelligence has spread over almost all ﬁelds of science and technology. Yet, computer vision remains in the heart of these advances when it comes to visual data analysis, offering the biggest big data and enabling advanced AI solutions to be developed. <br/>
        <br/>
        Undoubtedly, DNNs have shown remarkable success in many computer vision tasks, such as recognizing/localizing/segmenting faces, persons, objects, scenes, actions and gestures, and recognizing human expressions, emotions, as well as object relations and interactions in images or videos. Despite a wide range of impressive results, current DNN based methods typically depend on massive amounts of accurately annotated training data to achieve high performance, and are brittle in that their performance can degrade severely with small changes in their operating environment. Generally, collecting large scale training datasets is time-consuming, costly, and in many applications even infeasible, as for certain ﬁelds only very limited or no examples at all can  be gathered (such as visual inspection or medical domain), although for some computer vision tasks large amounts of unlabeled data may be relatively easy to collect, e.g., from the web or via synthesis. Nevertheless, labeling and vetting massive amounts of real-world training data is certainly difﬁcult,  expensive,  or  time-consuming,  as  it  requires the painstaking efforts of experienced human annotators or experts, and in many cases prohibitively costly or impossible due to some  reason,  such  as  privacy,  safety or ethic issues (e.g., endangered species, drug discovery, medical diagnostics and industrial inspection). <br/>
        <br/>
        DNNs lack the ability of learning from limited exemplars and fast generalizing to new tasks. However, real-word computer vision applications often require models that are able to (a) learn with few annotated samples, and (b) continually adapt to new data without forgetting prior knowledge. By contrast, humans can learn from just one   or a handful of examples (i.e., few shot learning), can do very long-term learning, and can form abstract models of a situation and manipulate these models to achieve extreme generalization. As a result, one of the next big challenges in computer vision is to develop learning approaches that are capable of addressing the important shortcomings of existing methods in this regard. Therefore, in order to address the current inefﬁciency of machine learning, there is pressing need to research methods, (1) to drastically reduce requirements for labeled training data, (2) to signiﬁcantly reduce the amount of data necessary to adapt models to new environments, and (3) to even use as little labeled training data as people need. </div>
    </div>
  </div>
</div>
	</div>
<div id="topics" class="section purple w-hidden-small w-hidden-tiny">
<div class="w-container">
  <h2 class="heading-3">Topics of Interest</h2>
  <div>
    <div class="text-block-9"> This special issue focuses on learning with fewer labels for computer vision tasks such as image classiﬁcation, object detection, semantic segmentation, instance segmentation, and many others and the topics of interest include (but are not limited to) the following areas:
      <ul>
        <li>Selfsupervised learning methods</li>
        <li>New methods for few-/zero-shot learning</li>
        <li>Meta-learning methods</li>
        <li>Life-long/continual/incremental learning methods</li>
        <li>Novel domain adaptation methods</li>
        <li>Semisupervised learning methods</li>
        <li>Weakly supervised learning methods</li>
      </ul>
    </div>
  </div>
</div>
</div>

<div id="dates" class="section-8">
  <div class="w-container">
    <h2 class="heading-11">Submission Deadline</h2>
    <div>
		<strong>Paper Submission Deadline: April 15, 2021.</strong>
      
    </div>
  </div>
</div>

<!--table表示创建表格  tr表示一行中的单元格 td表示单元格  th表示标题--> 
<!--thead表示表头  tbody表示表的内容  tfoot表示表脚--> 
<!--br换行 没有/br--> 
<!--colspan表示合并行单元格  rowspan表示合并列单元格-->

<div id="guest" class="section purple w-hidden-small w-hidden-tiny">
  <div class="w-container">
    <h2 class="heading-3">Guest Editors</h2>
    <div class="text-block-9">
      <ul>
        <li><strong><a href="http://www.ee.oulu.fi/~lili/LiLiuHomepage.html" class="link">Li Liu</a></strong></br>
          Associate Professor</br>
          National University of Defense Technology, China</br>
          Center for Machine Vision and Signal Analysis (CMVS), University of Oulu, Finland</br>
          li.liu@oulu.fi</li>
        <li><strong><a href="https://homepages.inf.ed.ac.uk/thospeda/" class="link">Timothy Hospedales</a></strong></br>
          Professor</br>
          University of Edinburgh, UK</br>
          Principal Scientist at Samsung AI Research Centre Alan Turing Institute Fellow</br>
          t.hospedales@ed.ac.uk</li>
        <li><strong><a href="http://yann.lecun.com/" class="link">Yann LeCun</a></strong></br>
          Silver Professor</br>
          New York University,  United  States VP and Chief AI Scientist at Facebook</br>
          yann@fb.com</li>
        <li><strong><a href="http://ise.thss.tsinghua.edu.cn/~mlong/" class="link">Mingsheng Long</a></strong></br>
          Associate Professor</br>
          Tsinghua University, China</br>
          mingsheng@tsinghua.edu.cn</li>
        <li><strong><a href="https://www.cs.rochester.edu/u/jluo/" class="link">Jiebo Luo</a></strong></br>
          Professor</br>
          University of Rochester, United States</br>
          jluo@cs.rochester.edu</li>
        <li><strong><a href="https://wlouyang.github.io/" class="link">Wanli Ouyang</a></strong></br>
          Senior Lecturer</br>
          University of Sydney, Australia</br>
          wanli.ouyang@sydney.edu.au</li>
        <li><strong><a href="https://scholar.google.com/citations?user=bjEpXBoAAAAJ&amp;hl=en" class="link">Matti Pietikäinen</a></strong></br>
          Professor (IEEE Fellow)</br>
          Center for Machine Vision and Signal Analysis University of Oulu, Finland</br>
          matti.pietikainen@oulu.ﬁ</li>
        <li><strong><a href="https://homes.esat.kuleuven.be/~tuytelaa/" class="link">Tinne Tuytelaars</a></strong></br>
          Professor</br>
          KU Leuven, Belgium </br>
          Tinne.Tuytelaars@esat.kuleuven.be</li>
      </ul>
    </div>
  </div>
</div>
<div class="section-6 w-hidden-small w-hidden-tiny">
<div class="w-container">
  <div>
    <h2 class="heading-7" align="center">Main Contacts</h2>
    <div class="newfontsize">If you have question, please contact : </br>
      <ul>
        <li><strong><em>Dr. Li Liu</em></strong> : li.liu@oulu.fi, dreamliu2010@gmail.com</br>
          National University of Defense Technology, China</br>
          Center for Machine Vision and Signal Analysis (CMVS), University of Oulu, Finland</li>
      </ul>
    </div>
  </div>
</div>
<script src="https://code.jquery.com/jquery-3.3.1.min.js" type="text/javascript" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><script src="https://uploads-ssl.webflow.com/5abe7e9055d981785ad0393e/js/webflow.2e96abf72.js" type="text/javascript"></script><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
</body>
</html>
